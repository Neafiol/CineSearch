{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_discr_ganre_arr_word2int\",\"r\") as f:\n",
    "    dataset=json.load(f)\n",
    "with open(\"gange\",\"r\") as f:\n",
    "    gange = json.load(f)\n",
    "with open(\"vocab\",\"r\") as f:\n",
    "    vocab = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextGanre(nn.Module):\n",
    "    def __init__(self,batch_size, vocab_size, embedding_dim, num_class, hidden_size=128):\n",
    "        super().__init__()\n",
    "        self.embedding_dim=embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.input_dim = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.basic_rnn = nn.LSTM(embedding_dim, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.clasifiter = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_class),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # (num_layers, batch_size, n_neurons)\n",
    "        self.c_0 = torch.zeros(1,self.batch_size, self.hidden_size)\n",
    "        self.h_0 = torch.zeros(1,self.batch_size, self.hidden_size)\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (self.h_0 , self.c_0) = self.basic_rnn(embedded, (self.h_0 , self.c_0))\n",
    "        \n",
    "        output = self.clasifiter(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 16\n",
    "NUN_CLASS = len(gange)\n",
    "NGRAMS = 2\n",
    "BATCH_SIZE = 16\n",
    "VOCAB_SIZE=len(vocab)\n",
    "N_EPOCHS =5 \n",
    "\n",
    "model = TextGanre(BATCH_SIZE, VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    d=[b[\"ganre\"] for b in batch]\n",
    "    label = torch.tensor(d).to(torch.float)\n",
    "    text = [torch.tensor(b[\"discr\"]).to(torch.int64) for b in batch]\n",
    "    \n",
    "    text=torch.nn.utils.rnn.pad_sequence( text , batch_first=True)\n",
    "    return text.view(-1,len(batch)), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acur(pred, result):\n",
    "\n",
    "    result=result.tolist()\n",
    "    s = 0\n",
    "    c = 1\n",
    "    \n",
    "    for i,p in enumerate(pred[-1]):    \n",
    "        p=p.tolist()\n",
    "        count = sum(result[i])\n",
    "        \n",
    "        top = sorted(p)[-int(count):]\n",
    "        for t in top:\n",
    "            s+=result[i][p.index(t)]\n",
    "        c+=count\n",
    "            \n",
    "    return s/c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    \n",
    "    for i, (text, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()        \n",
    "        model.init_hidden() \n",
    "        \n",
    "        text, cls = text.to(device), cls.to(device)\n",
    "        try:\n",
    "            output = model(text)\n",
    "\n",
    "            loss = criterion(output, cls)\n",
    "            train_loss += loss.detach().item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_acc += 1 - abs((output-cls).mean())\n",
    "\n",
    "       \n",
    "        except:\n",
    "            print(\"Error\")\n",
    "            break\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / i, train_acc / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "train_len = int(len(dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = random_split(dataset, [train_len, len(dataset) - train_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextGanre(\n",
       "  (embedding): Embedding(69127, 16)\n",
       "  (basic_rnn): LSTM(16, 128)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (clasifiter): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=26, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "Epoch: 1  | time in 7 minutes, 20 seconds\n",
      "\tLoss: 0.6960(train)\t|\tAcc: 91.3%(train)\n",
      "Error\n",
      "Epoch: 2  | time in 6 minutes, 24 seconds\n",
      "\tLoss: 0.6931(train)\t|\tAcc: 91.5%(train)\n",
      "Error\n",
      "Epoch: 3  | time in 679 minutes, 50 seconds\n",
      "\tLoss: 0.6931(train)\t|\tAcc: 91.5%(train)\n",
      "Error\n",
      "Epoch: 4  | time in 5 minutes, 53 seconds\n",
      "\tLoss: 0.6931(train)\t|\tAcc: 91.5%(train)\n",
      "Error\n",
      "Epoch: 5  | time in 5 minutes, 58 seconds\n",
      "\tLoss: 0.6931(train)\t|\tAcc: 91.5%(train)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.MultiLabelSoftMarginLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "#     valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "    \n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "#     print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Porter:\n",
    "\tPERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "\tREFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "\tADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\n",
    "\tPARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\n",
    "\tVERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "\tNOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "\tRVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\n",
    "\tDERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\n",
    "\tDER = re.compile(u\"ость?$\")\n",
    "\tSUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\n",
    "\tI = re.compile(u\"и$\")\n",
    "\tP = re.compile(u\"ь$\")\n",
    "\tNN = re.compile(u\"нн$\")\n",
    "\n",
    "\tdef stem(word):\n",
    "\t\tword = word.lower()\n",
    "\t\tword = word.replace(u'ё', u'е')\n",
    "\t\tm = re.match(Porter.RVRE, word)\n",
    "\t\tif m.groups():\n",
    "\t\t\tpre = m.group(1)\n",
    "\t\t\trv = m.group(2)\n",
    "\t\t\ttemp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "\t\t\tif temp == rv:\n",
    "\t\t\t\trv = Porter.REFLEXIVE.sub('', rv, 1)\n",
    "\t\t\t\ttemp = Porter.ADJECTIVE.sub('', rv, 1)\n",
    "\t\t\t\tif temp != rv:\n",
    "\t\t\t\t\trv = temp\n",
    "\t\t\t\t\trv = Porter.PARTICIPLE.sub('', rv, 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttemp = Porter.VERB.sub('', rv, 1)\n",
    "\t\t\t\t\tif temp == rv:\n",
    "\t\t\t\t\t\trv = Porter.NOUN.sub('', rv, 1)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\trv = temp\n",
    "\t\t\telse:\n",
    "\t\t\t\trv = temp\n",
    "\t\t\t\n",
    "\t\t\trv = Porter.I.sub('', rv, 1)\n",
    "\n",
    "\t\t\tif re.match(Porter.DERIVATIONAL, rv):\n",
    "\t\t\t\trv = Porter.DER.sub('', rv, 1)\n",
    "\n",
    "\t\t\ttemp = Porter.P.sub('', rv, 1)\n",
    "\t\t\tif temp == rv:\n",
    "\t\t\t\trv = Porter.SUPERLATIVE.sub('', rv, 1)\n",
    "\t\t\t\trv = Porter.NN.sub(u'н', rv, 1)\n",
    "\t\t\telse:\n",
    "\t\t\t\trv = temp\n",
    "\t\t\tword = pre+rv\n",
    "\t\treturn word\n",
    "\tstem=staticmethod(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preproc(text):\n",
    "    reg = re.compile('[^а-яА-Я ]')\n",
    "    text = (reg.sub('', text))\n",
    "    text=re.compile(\"\\s+\").sub(\" \",text).lower()\n",
    "    \n",
    "    res=[]\n",
    "    for w in text.split(\" \"):\n",
    "        try:\n",
    "            if len(w)>4:\n",
    "                try:\n",
    "                    res.append(vocab[Porter.stem(w)])\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                res.append(vocab[w])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16206, 62696, 23914]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preproc(\"Очень страшный фильм\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    text, _ = generate_batch([{\n",
    "        \"discr\":text_preproc(text),\n",
    "        \"ganre\":[0]\n",
    "    }])\n",
    "    return text\n",
    "\n",
    "test = predict(\"Там, где круглый год лежат снега, а небо озаряет северное сияние, живет Ледяная принцесса Лилли с голубыми, как древний лед, волосами. Однажды Лилли и её друг, полярный медведь Лимбо, встречают юного дракона, который не умеет извергать пламя. Лилли обещает помочь ему. Но путь, который их ждет, будет не из легких, впереди новых друзей ждет немало приключений и опасных испытаний.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9580,  0.9682, -0.0804,  0.9751,  0.9522, -0.9875,  0.9740, -0.9696,\n",
       "        -0.0681, -0.9734,  0.9715, -0.9622,  0.9677,  0.9236,  0.9750, -0.9862,\n",
       "         0.9149, -0.9823, -0.9770,  0.2799, -0.9873, -0.9828,  0.9732, -0.9641,\n",
       "         0.9777,  0.9688, -0.9783,  0.9482, -0.9466, -0.9739, -0.9594, -0.9714,\n",
       "        -0.9650,  0.9774, -0.9713,  0.9609,  0.9692,  0.9677, -0.9722, -0.9776,\n",
       "        -0.9711, -0.9756, -0.9769, -0.9545, -0.9815,  0.9394,  0.9857,  0.9662,\n",
       "        -0.9363,  0.9793,  0.9779,  0.9407,  0.9431,  0.9775,  0.6681,  0.9719,\n",
       "        -0.9808, -0.9688,  0.9632, -0.9782,  0.8912,  0.9567, -0.9486,  0.9992,\n",
       "        -0.9813,  0.9238, -0.9760, -0.9483, -0.9815, -0.9691,  0.9688,  0.9533,\n",
       "         0.9745,  0.9714, -0.9805, -0.9824,  0.9893,  0.9746,  0.9785, -0.9628,\n",
       "        -0.9949,  0.9448, -0.9620, -0.9608, -0.9812,  0.9766,  0.9863, -0.9704,\n",
       "         0.9885,  0.9213,  0.9692, -0.8247, -0.9814, -0.9842,  0.9234,  0.9443,\n",
       "         0.9683,  0.9837, -0.9554,  0.9821, -0.9114, -0.9964, -0.9784, -0.9785,\n",
       "         0.9738,  0.9733, -0.9512,  0.9616, -0.9731, -0.9212, -0.9807, -0.9675,\n",
       "         0.9911, -0.9469, -0.0057, -0.0842,  0.9433, -0.9407,  0.9681, -0.9595,\n",
       "         0.8514,  0.9669, -0.9804, -0.9806,  0.9100,  0.9705,  0.9840, -0.9616],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.h_0 = torch.zeros(1,1, 128)\n",
    "newmodel.c_0 = torch.zeros(1,1, 128)\n",
    "\n",
    "pred=newmodel(test)\n",
    "pred[0][-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Боевик\n"
     ]
    }
   ],
   "source": [
    "top = sorted(pred)[-5:]\n",
    "for t in top:\n",
    "    print(gange[pred.index(t)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = torch.nn.Sequential(*(list(model.children())[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Petr\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Petr\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Embedding. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Users\\Petr\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(newmodel, \"model_lstm_short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
